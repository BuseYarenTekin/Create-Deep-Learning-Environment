{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GPU Usage.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4wNweFKUtLs"
      },
      "source": [
        "**<h2>GPU Usage on Your Local Computer / Google Colab</h2>**\n",
        "\n",
        "In this notebook you will connect to a GPU, and then run some basic TensorFlow operations on both the CPU and a GPU, observing the speedup provided by using the GPU.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gycQ8yXEUuR4"
      },
      "source": [
        "\n",
        "#### Enabling and testing the GPU\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6QaxT1MUyTZ"
      },
      "source": [
        "First, you'll need to enable GPUs for the notebook:\n",
        "\n",
        "1.  Navigate to Edit→Notebook Settings\n",
        "2.  Select GPU from the Hardware Accelerator drop-down"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9aYa4bGU19O"
      },
      "source": [
        "### Installing TensorFlow GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msy-cI0dYKWE"
      },
      "source": [
        "As a first step, we need to install *tensorflow-gpu*.\n",
        "\n",
        "If you are going to install it on your computer, you should follow these steps.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAq3g9KZY_b1"
      },
      "source": [
        "As a result of this code, you will have the latest version tensorflow gpu."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3-KoLaBUs6M"
      },
      "source": [
        "pip install tensorflow-gpu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DST_SVaUUhzr"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6gaNaQJXBoj"
      },
      "source": [
        "If the TensorFlow version you want to use is specific, install it by entering the version name."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQ2lPgeGW1VI"
      },
      "source": [
        "pip install tensorflow-gpu==1.15.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5l8fjfBwW4Y_"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHPA7omxZCGh"
      },
      "source": [
        "### Checking installed TensorFlow GPU version"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRzHrWG-ZO_Q"
      },
      "source": [
        "pip show tensorflow-gpu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVFrnNL7Zg3r"
      },
      "source": [
        "As you can see, the latest version of TensorFlow has been installed. If you want to use a specific version distribution, it is necessary to install with the version name."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awV9GT2-ZmPz"
      },
      "source": [
        "pip install tensorflow-gpu==1.15.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PEaJ2-zbXvP"
      },
      "source": [
        "If you are also getting warnings as above, it is because of:\n",
        "- Other libraries that came with the last version of tensorflow-gpu that we installed before are not uninstall, so they have version conflicts with the newly installed version. Decide on the version you want to use and use only that version distribution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DwOri2paJHd"
      },
      "source": [
        "To check the new TensorFlow version installed, work again with the command.\n",
        "```\n",
        "pip show packagename\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScjhfNh-ZoaG"
      },
      "source": [
        "pip show tensorflow-gpu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlAVfl0Nbp56"
      },
      "source": [
        "### Listing Eligible CPU and GPU Devices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2CLCZwhboeE"
      },
      "source": [
        "Next, we are at the step of showing all possible devices that can be used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TKwTSAWbfWQ"
      },
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PH74XhDicL3U"
      },
      "source": [
        "\n",
        "4 devices are shown in the list here. 2 of them are a concept excluding CPU and GPU.\n",
        "\n",
        "As mentioned in the docs, XLA stands for \"accelerated linear algebra\". It's Tensorflow's relatively new optimizing compiler that can further speed up your ML models' GPU operations by combining what used to be multiple CUDA kernels into one (simplifying because this isn't that important for your question).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e__cs19gb9yT"
      },
      "source": [
        "In the next step, the default device name used will be listed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XvbrL7Tb2kd"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECNwL_F_dKXo"
      },
      "source": [
        "### Speed Comparison in Model Tutorials for GPU and CPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1swEBSKdCG5"
      },
      "source": [
        "import tensorflow as tf\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "training_images=training_images / 255.0\n",
        "test_images=test_images / 255.0\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "\n",
        "test_loss = model.evaluate(test_images, test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsnrFCtzd30O"
      },
      "source": [
        "As you can see, ETA times are very short. One minute to train almost this amount of data! Now, by following the steps below, let's choose the hardware CPU for the runtime and see how we will experience a difference in speed.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "You'll need to enable CPUs for the notebook:\n",
        "\n",
        "\n",
        "1.  Navigate to Edit→Notebook Settings\n",
        "2.  Select None from the Hardware Accelerator drop-down"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMwESnqBeZMU"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1shUn5Uen6w"
      },
      "source": [
        "And now when we test whether it is using GPU or not, we see that the value of None comes out. After making sure we are using a CPU, we can provide the training for this as well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxkJv3Xzeo6Z"
      },
      "source": [
        "import tensorflow as tf\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "training_images=training_images / 255.0\n",
        "test_images=test_images / 255.0\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "\n",
        "test_loss = model.evaluate(test_images, test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4rxCwQxfsXx"
      },
      "source": [
        "Here, as the number of data increases and the problem becomes more intense, the difference between training will become much wider.\n",
        "\n",
        "Since there is not a very large data set in this example line of code, there are no big differences between CPU and GPU when processing data. However, there will be a significant difference when processing big data.\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPCQRHIjQqBe"
      },
      "source": [
        "# A sample GPU setup on the local computer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwjc1CKCQzGT"
      },
      "source": [
        "If you want to learn the features of your graphics card, you can learn the features of your graphics card by typing **dxdiag**. Or instead, you can run the command below on your computer's terminal."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqYVJA7jUYdC"
      },
      "source": [
        "### Controlling graphic card name"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0K0Jy2LQ-lm"
      },
      "source": [
        "wmic path win32_VideoController get name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLYI7qVvRn4d"
      },
      "source": [
        "Since I do not want to work in the base area of the machine, I create a virtual environment and I do this with Conda. You can also use Mini Conda if you wish."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PV7sGQbIUdbU"
      },
      "source": [
        "### Creating virtual environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "967_3HG_RXpq"
      },
      "source": [
        "conda create -n virtualenv python=3.6\n",
        "conda activate virtualenv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFO-dnEpUiKo"
      },
      "source": [
        "### TensorFlow GPU Installation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVPXJim4UCqy"
      },
      "source": [
        "To use GPU with TensorFlow, it is necessary to install the tensorflow-gpu library. If loading with conda, the appropriate CUDA and cuDNN versions will also be displayed during the process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VY1ze-3qTnO6"
      },
      "source": [
        "conda install tensorflow-gpu==1.15.0 \n",
        "#pip install tensorflow-gpu==1.15.0 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4rGYueFTUSWJ"
      },
      "source": [
        "After all these stages, TensorFlow GPU must be installed. If you wish, you can control the terminal with the following commands."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-pmGR4pUMDs"
      },
      "source": [
        "import tensorflow as tf\n",
        "sess=tf.Session(config=tf.ConfigProto(log_device_placement=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaNL5GT_4BeG"
      },
      "source": [
        "### Keras Installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkUjT36v4EmK"
      },
      "source": [
        "pip install keras==2.2.5"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}